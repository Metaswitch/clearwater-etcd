{
    "alarms": [
        {
            "index": 9000,
            "name": "QUEUE_MANAGER_PROCESS_FAIL",
            "cause": "SOFTWARE_ERROR",
            "levels": [
                {
                    "severity": "CLEARED",
                    "details": "The queue manager process has been restored to normal operation.",
                    "description": "Queue manager: Process failure cleared.",
                    "cause": "The queue manager process has been restored to normal operation. The previously issued alarm has been cleared.",
                    "effect": "Changes to shared config will be synchronized across the cluster.",
                    "action": "No action."
                },
                {
                    "severity": "CRITICAL",
                    "details": "Monit has detected that the local queue manager process has failed. A restart will automatically be attempted. If this alarm does not clear, the queue manager process may have been stopped or an unrecoverable failure may have occurred.",
                    "description": "Queue manager: Process failure.",
                    "cause": "Monit has detected that the local queue manager process has failed. A restart will automatically be attempted.",
                    "effect": "Changes to shared config will not be synchronized across the cluster.",
                    "action": "If this alarm does not clear, the queue manager process may have been stopped or an unrecoverable failure may have occurred. Contact your support representative."
                }
            ]
        },
        {
            "name": "GLOBAL_CONFIG_RESYNCHING",
            "index": 9001,
            "cause": "DATABASE_INCONSISTENCY",
            "levels": [
                {
                    "severity": "CLEARED",
                    "description": "etcd: Shared configuration is now consistent across the deployment.",
                    "details": "All shared configuration has been synchronized across the deployment.",
                    "cause": "Shared configuration is now consistent across the deployment.",
                    "effect": "Changes to shared configuration have been picked up by all nodes in the deployment.",
                    "action": "No action."
                },
                {
                    "severity": "MINOR",
                    "description": "etcd: Shared configuration is being synchronized across the cluster.",
                    "details": "Shared configuration is being synchronized across the cluster. This involves restarting the clearwater processes on individual nodes.",
                    "cause": "A change has been made to shared configuration.",
                    "effect": "Changes to shared configuration are synchronized across the cluster and processes are restarted to pick up the changes.",
                    "action": "Monitor this alarm, and wait for it to clear. Shared configuration can take up to 30 seconds per node to percolate through the deployment. If the alarm doesn't clear in a timely fashion, contact your support representative."
                },
                {
                    "severity": "CRITICAL",
                    "description": "etcd: A node has failed to start successfully after receiving new shared configuration.",
                    "details": "A node has failed to start successfully after receiving new shared configuration. Check that the shared configuration is valid, and the node is alive.",
                    "cause": "A change has been made to shared configuration which has been rejected by a process on another node.",
                    "effect": "Service may have been lost. Check for other raised alarms to determine which process has failed to start and what effect that has.",
                    "action": "Check that the shared configuration is valid. If it isn't, correct it and re-upload it. If the alarm still doesn't clear, contact your support representative."
                }
            ]
        },
        {
            "name": "LOCAL_CONFIG_RESYNCHING",
            "index": 9002,
            "cause": "DATABASE_INCONSISTENCY",
            "levels": [
                {
                    "severity": "CLEARED",
                    "description": "etcd: Shared configuration has been learned by the local node.",
                    "details": "All shared configuration has been synchronized to the local node.",
                    "cause": "All shared configuration has been synchronized to the local node. Once the local node has joined any backend clusters, it may be safely added to DNS to allow it to start providing service. The previous issued alarm has been cleared",
                    "effect": "Shared configuration is up to date on the local node.",
                    "action": "No action."
                },
                {
                    "severity": "MINOR",
                    "description": "etcd: Shared configuration is being synchronized on this node.",
                    "details": "Shared configuration is being synchronized on this node. This involves restarting the processes on this node.",
                    "cause": "This node is picking up a change that has been made to shared configuration.",
                    "effect": "Processes on this node are restarted to pick up the changes to shared configuration.",
                    "action": "Monitor this alarm, and wait for it to clear. Shared configuration can take up to 30 seconds to be picked up. If the alarm doesn't clear in a timely fashion, contact your support representative."
                },
                {
                    "severity": "CRITICAL",
                    "description": "etcd: This node has failed to start successfully after receiving new shared configuration.",
                    "details": "This node has failed to start successfully after receiving new shared configuration. Check that the shared configuration is valid, and this node is alive.",
                    "cause": "A change has been made to shared configuration which has been rejected by a process on this node.",
                    "effect": "Service may have been lost. Check for other raised alarms to determine which process has failed to start and what effect that has.",
                    "action": "Check that the shared configuration is valid. If it isn't, correct it and re-upload it. If the alarm still doesn't clear, contact your support representative."
                }
            ]
        },
        {
            "name": "GLOBAL_CHRONOS_GR_CONFIG_RESYNCHING",
            "index": 9003,
            "cause": "DATABASE_INCONSISTENCY",
            "levels": [
                {
                    "severity": "CLEARED",
                    "description": "etcd: Chronos GR configuration is now consistent across the deployment.",
                    "details": "All Chronos GR configuration has been synchronized across the deployment.",
                    "cause": "Chronos GR configuration is now consistent across the deployment.",
                    "effect": "Changes to Chronos GR configuration have been picked up by all nodes in the deployment.",
                    "action": "No action."
                },
                {
                    "severity": "MINOR",
                    "description": "etcd: Chronos GR configuration is being synchronized across the cluster.",
                    "details": "Chronos GR configuration is being synchronized across the cluster. This involves restarting the Chronos processes on individual nodes.",
                    "cause": "A change has been made to Chronos GR configuration.",
                    "effect": "Changes to Chronos GR configuration are synchronized across the cluster and processes are restarted to pick up the changes.",
                    "action": "Monitor this alarm, and wait for it to clear. If the alarm doesn't clear in a timely fashion, contact your support representative."
                },
                {
                    "severity": "CRITICAL",
                    "description": "etcd: A Chronos node has failed to resync successfully after receiving new Chronos GR configuration.",
                    "details": "A Chronos node has failed to resync successfully after receiving new Chronos GR configuration. Check that the Chronos GR configuration is valid, and the node is alive.",
                    "cause": "A change has been made to Chronos GR configuration which has led to the Chronos node not being able to successfully resync.",
                    "effect": "Timer redundancy has been lost",
                    "action": "Check that the Chronos GR configuration is valid. If it isn't, correct it and re-upload it. If the alarm still doesn't clear, contact your support representative."
                }
            ]
        },
        {
            "name": "LOCAL_CHRONOS_GR_CONFIG_RESYNCHING",
            "index": 9004,
            "cause": "DATABASE_INCONSISTENCY",
            "levels": [
                {
                    "severity": "CLEARED",
                    "description": "etcd: Chronos GR configuration has been learned by the local node.",
                    "details": "All Chronos GR configuration has been synchronized to the local node.",
                    "cause": "All Chronos GR configuration has been synchronized to the local node.",
                    "effect": "Chronos GR configuration is up to date on the local node.",
                    "action": "No action."
                },
                {
                    "severity": "MINOR",
                    "description": "etcd: Chronos GR configuration is being synchronized on this node.",
                    "details": "Chronos GR configuration is being synchronized on this node. This involves restarting the Chronos processes on this node.",
                    "cause": "This node is picking up a change that has been made to Chronos GR configuration.",
                    "effect": "The Chronos process on this node is restarted to pick up the changes to Chronos GR configuration.",
                    "action": "Monitor this alarm, and wait for it to clear. If the alarm doesn't clear in a timely fashion, contact your support representative."
                },
                {
                    "severity": "CRITICAL",
                    "description": "etcd: This node has failed to resync successfully after receiving new Chronos GR configuration.",
                    "details": "This node has failed to resync successfully after receiving new Chronos GR configuration. Check that the Chronos GR configuration is valid, and this node is alive.",
                    "cause": "A change has been made to Chronos GR configuration which has led to the Chronos node not being able to successfully resync.",
                    "effect": "Timer redundancy has been lost.",
                    "action": "Check that the Chronos GR configuration is valid. If it isn't, correct it and re-upload it. If the alarm still doesn't clear, contact your support representative."
                }
            ]
        }
    ]
}
